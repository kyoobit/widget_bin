alias oneliners='cat $HOME/repos/widget_bin/oneliners.txt';

## Age - a file encryption tool
age-keygen -o key.txt
tar cz data | age -r $(cat key.txt) > data.tar.gz.age
age --decryptt -i key.txt data.tar.gz.age > data.tar.gz

apropos <WORD>

## AWK|GAWK|MAWK|...
free_kbytes_total=$(free --kibi --total | awk '/^Total:/ {print $2}')
ps -eo rss,command --sort=-rss | awk -v total="$free_kbytes_total" '
  NR==1 { printf "%6s %6s %s\n", "%MEM", "RSS", "COMMAND"; next }
  $1 > 10240 { printf "%6.2f %6d %s\n", ($1/total*100), $1, substr($0, index($0, $2))}
'

## BASH
export LC_TIME='C.UTF-8';
export PS1='[\D{%F %T}] \u@\h:\w\$ ';
#!/bin/bash
#!/usr/bin/env bash
$ foo=1:2:3:4:5; echo ${foo##*:} => 5
$ foo=1:2:3:4:5; echo ${foo#*:}  => 2:3:4:5
$ foo=1:2:3:4:5; echo ${foo%%:*} => 1
$ foo=1:2:3:4:5; echo ${foo%:*}  => 1:2:3:4
$ foo=""; echo ${foo:-bar}; foo="foo"; echo ${foo:-bar}; foo=""; echo ${foo:-bar};
$ foo=""; echo ${foo}; echo ${foo:=bar}; echo ${foo};
$ foo=""; bar="bar"; echo ${foo:+bar};
$ foo=""; echo ${foo:?"error message"}; echo ${foo:?};
$ foo=""; echo ${foo:?"error message"}; => -bash: foo: error message
$ foo=""; echo ${foo:?}; => -bash: foo: parameter null or not set
$ foo=""; echo ${foo}; foo=${1-false}; echo ${foo}; if [[ ${foo} == false ]]; then echo "hit"; else echo "miss"; fi;
$ echo "addr=10."$((RANDOM%255)).$((RANDOM%255)).$((RANDOM%255))
$ foo="ABCDEF"; echo ${foo:0:2} => AB
$ foo="ABCDEF"; echo ${foo: -2} => EF
for ((n=14; n<=17; n++)); do echo ${n}; done

for i in $(cat list); do something; read PAUSE; done
for i in $(cat list); do something | shuf | head -n 1; done

while read -r line; do echo "$line" | awk '{print $2}'; done < <( ... )

## help mapfile (alias: readarray)
readarray -t my_array < <(some command that returns lines);
mapfile -t -O 10 my_array < <(some command that returns lines);
echo "${#my_array[@]} lines return";
for item in "${my_array[@]}"; do some work...; done

cat << EOF > some-file.txt
Multi-line blob of text
EOF

## Command-Line move and delete commands:
┌──────────┬───────────────────────┬───────────────────────────────────────────┐
│ GROUP    │ <---  DIRECTION  ---> │ USAGE                                     │
├──────────┼───────────┬───────────┼───────────────────────────────────────────┤
│          │ control+b │ control+f │ move one letter                           │
│ MOVING   │ option+b  │ option+f  │ move one word                             │
│          │ control+a │ control+e │ move to start/end of line                 │
├──────────┼───────────┼───────────┼───────────────────────────────────────────┤
│ DELETING │ control+w │ option+d  │ delete one word                           │
│ DELETING │ control+u │ control+k │ delete to start/end of line               │
└──────────┴───────────┴───────────┴───────────────────────────────────────────┘

crontab (but you know you should use systemd timers instead)
# .------------- minute (0 - 59) */10 == every ten minutes
# |  .---------- hour (0 - 23)
# |  |  .------- day of month (1 - 31)
# |  |  |  .---- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .- day of week (0 - 6) (Sunday=0 or 7) 
# |  |  |  |  |  -or- sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |  TEST: env > ~/cronenv; env - `cat ~/cronenv` /bin/sh
# *  *  *  *  *  <command to be executed> 2>&1 >> <always log>

sudo dd if=/dev/zero of=/dev/sdj bs=1M status=progress <--- zero a disk to flush out sectors
dd if=/path/to/some.iso of=/dev/disk4 bs=1m
dd if=/dev/urandom of=test.obj bs=1M count=16 iflag=fullblock
dd if=/dev/random bs=1024 count=102400 of=100MB.file
head -c 16M /dev/urandom > test.obj <--- like dd

## Size matters: bits v bytes
1 Yobibyte  (YiB)  2^80 bytes .... 1208925819614629174706176 bytes
1 Yottabyte (YB)  10^24 bytes .... 1000000000000000000000000 bytes
1 Yottabit  (Yb)  10^24 bits  .... 1000000000000000000000000 bits
1 Zebibyte  (ZiB)  2^70 bytes ....... 1180591620717411303424 bytes
1 Zettabyte (ZB)  10^21 bytes ....... 1000000000000000000000 bytes
1 Zettabit  (Zb)  10^21 bits  ....... 1000000000000000000000 bits
1 Exbibyte  (EiB)  2^60 bytes .......... 1152921504606846976 bytes
1 Exabyte   (EB)  10^18 bytes .......... 1000000000000000000 bytes
1 Exabit    (Eb)  10^18 bits  .......... 1000000000000000000 bits
1 Pebibyte  (PiB)  2^50 bytes ............. 1125899906842624 bytes
1 Petabyte  (PB)  10^15 bytes ............. 1000000000000000 bytes
1 Petabit   (Pb)  10^15 bits  ............. 1000000000000000 bits
1 Tebibyte  (TiB)  2^40 bytes ................ 1099511627776 bytes
1 Terabyte  (TB)  10^12 bytes ................ 1000000000000 bytes
1 Terabit   (Tb)  10^12 bits  ................ 1000000000000 bits
1 Gibibyte  (GiB)  2^30 bytes ................... 1073741824 bytes
1 Gigabyte  (GB)  10^9  bytes ................... 1000000000 bytes
1 Gigabit   (Gb)  10^9  bits  ................... 1000000000 bits
1 Mebibyte  (MiB)  2^20 bytes ...................... 1048576 bytes
1 Megabyte  (MB)  10^6  bytes ...................... 1000000 bytes
1 Megabit   (Mb)  10^6  bits  ...................... 1000000 bits
1 Kibibyte  (KiB)  2^10 bytes ......................... 1024 bytes
1 Kibabyte  (KB)  10^3  bytes ......................... 1000 bytes
1 Kilobit   (Kb)  10^3  bits  ......................... 1000 bits
1 byte      (B)      8  bits  ............................ 8 bits
1 bits      (b)      1  bit   ............................ 0 || 1

diff -ub <(jq -S . <A>.json ) <(jq -S . <B>.json )
diff --from-file <A> <B> <C> ... <--- diff file A against one or more files

dig +trace <FQDN> @<NS>
dig <FQDN> +nocomments +noquestion +noauthority +noadditional +noststs (same as: +short?)

dpkg -S dig | grep bin <--- like `dnf whatprovides dig`
sudo install apt-file && sudo apt-file update && apt-file search bin/dig <--- like `dnf whatprovides dig`
sudo dpkg-reconfigure tzdata || sudo timedatectl set-timezone Etc/UTC
sudo dpkg-reconfigure -plow console-setup <--- console font size: Terminus 16x32
sudo /bin/rm -v /etc/ssh/ssh_host_* && sudo dpkg-reconfigure openssh-server && sudo systemctl restart ssh <--- rekey a host

echo "send a message" | wall

ethtool <DEVICE>
ethtool -m <DEVICE>

systemctl status firewalld
sudo firewall-cmd --get-zones
sudo firewall-cmd --get-active-zones
sudo firewall-cmd --set-default-zone=public
sudo firewall-cmd --list-all
sudo grep LogDenied /etc/firewalld/firewalld.conf
sudo sed -i 's|LogDenied=off|LogDenied=all|' /etc/firewalld/firewalld.conf
sudo firewall-cmd --reload

sudo fdisk -l
sudo fdisk /dev/sda
n p
w
sudo wipefs --all /dev/sda --force
sudo mkfs.xfs -f /dev/sda1

find /some/path -perm -g+w
find /some/path -type f -name '*PATTERN*' -exec rm {} \;
find /some/path -mtime +30 -delete
find /some/path -name '*PATTERN*' -exec md5sum {} \;
find /some/path -name '*PATTERN*' -mmin -30
find /some/path -regextype posix-awk -regex ".*PATTERN.*" -type f -mmin -15

sudo gdb <path to binary> <path to core file>


## Help message                                                      <--- getopt
read -r -d '' help_message << EOM                                    <--- getopt
usage: $(basename $0) [-h] [-a] [-b] [-c <value>] [<other>[ ...]]    <--- getopt
                                                                     <--- getopt
About...                                                             <--- getopt
                                                                     <--- getopt
arguments:                                                           <--- getopt
  -h          Show this help message and exit.                       <--- getopt
  -a          Some option without a value                            <--- getopt
  -b          Another option without a value                         <--- getopt
  -c <value>  Some option with a value                               <--- getopt
  -v          Verbose mode                                           <--- getopt
                                                                     <--- getopt
Example usage:                                                       <--- getopt
  $(basename $0) -a foo bar                                          <--- getopt
EOM                                                                  <--- getopt
                                                                     <--- getopt
# Parse command-line arguments using getopt                          <--- getopt
# getopt [options] -o|--options optstring [options] [--] parameters  <--- getopt
# https://www.man7.org/linux/man-pages/man1/getopt.1.html            <--- getopt
while getopts 'habc:v' opt; do                                       <--- getopt
    case "${opt}" in                                                 <--- getopt
        h ) printf "${help_message}\n\n"; exit 0;;                   <--- getopt
        a ) x="x";;                                                  <--- getopt
        b ) y="y";;                                                  <--- getopt
        c ) z="${OPTARG}";;                                          <--- getopt
        v ) verbose="verbose";;                                      <--- getopt
    esac                                                             <--- getopt
done                                                                 <--- getopt
# Shift off the arguments from the path(s)                           <--- getopt
shift "$((OPTIND - 1))";                                             <--- getopt
for other_arg in "${@}"; do                                          <--- getopt
    printf "other_arg=${other_arg}\n"                                <--- getopt
done                                                                 <--- getopt


geo: curl -i http://ip-api.com/json/${ADDRESS} | jq


## Gherkin issue template
**As a** [role]
**I need** [function]
**So that** [benefit]

### Details and Assumptions
* [document what you know]

### Acceptance Criteria

```gherkin
Given [some context]
When [certain action is taken]
Then [the outcome of action is observed]
```

## Git branch and merge cycle
git clone <url>
git checkout main
git pull
git checkout -b <branch name>
  feature/<feature-id>/<description>
  fix/<issue-id>/<description>
  release/<release-string>
git merge main
  ...work, work, whoops ...
git stash (stash changes)
git reset --soft (keeps local changes)
git reset --hard (destructive to last commit)
git checkout . (????)
  ...work, work, work ...
git status
git add <files>
git commit -m '<a useful message>'
  ...whoops, forgot something, edit and:
git commit --amend --no-edit
git push -u origin <branch name>
  ...follow open pull request instructions...
git checkout main
git pull
git branch -d <branch name>
git stash pop (restore stashed changes)
  ...fork! rollback
git checkout -b <revert_something>
git log -n 3
git revert --no-commit --mainline 1 HEAD~1
git revert --continue
git diff HEAD..origin/main
git push
git checkout production; git pull; git checkout staging; git merge production; git pull (sync from prod to staging)

## GPG - GNU Privacy Guard (PGP): ~/.gnupg
gpg --gen-random --armor 1 16
gpg --dump-options
gpg --rfc4880
gpg --generate-key
gpg --full-generate-key
## Generate an "armored" key in ASCII
gpg --import prikey.asc && shred -uvz prikey.asc
gpg --list-secret-keys --keyid-format LONG
gpg --armor --export-secret-keys you@example.net > prikey.asc
gpg --armor --export you@example.net > pubkey.asc
## Encrypt a message:
gpg --import pubkey.asc
gpg --encrypt --recipient you@example.net --armor < in.txt -o out.txt
## Sign a message:
gpg --sign in.txt --output signed.sig
gpg --clearsign in.txt
gpg --output out.sig --detach-sig in.txt
gpg --verify out.sig in.txt
## Decrypt a message:
gpg --decrypt out.txt

grep --line-buffered --color=always
grep --line-buffered --color=always <PATTERN> || grep --color -E "^|<PATTERN>"
grep -oE "[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}" <--- IPv4-ish

for n in {a..t}; do sudo hdparm -t /dev/sd${n}; done


sudo -u hdfs /usr/local/hadoop/bin/hdfs dfsadmin -report
sudo -u hdfs /usr/local/hadoop/bin/hdfs --daemon status journalnode
sudo -u hdfs /usr/local/hadoop/bin/hdfs --daemon status namenode
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -getAllServiceState
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -getServiceState mgm1
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -checkHealth mgm1
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -transitionToActive mgm1 --forcemanual
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -transitionToStandby mgm2
sudo -u hdfs /usr/local/hadoop/bin/hdfs haadmin -failover -forceactive mgm1 mgm2
sudo -u yarn /usr/local/hadoop/bin/yarn rmadmin -getAllServiceState
sudo -u yarn /usr/local/hadoop/bin/yarn rmadmin -checkHealth mgm1
sudo -u yarn /usr/local/hadoop/bin/yarn rmadmin -getServiceState mgm1
sudo -u yarn /usr/local/hadoop/bin/yarn rmadmin -transitionToActive mgm2 --forceactive
sudo -u yarn /usr/local/hadoop/bin/yarn rmadmin -transitionToStandby --force mgm2
sudo -u hdfs /usr/local/hadoop/bin/hdfs --daemon status zkfc
sudo -u zookeeper /usr/local/zookeeper/bin/zkServer.sh --config /usr/local/zookeeper/conf status
sudo -u hbase /usr/local/hadoop/bin/hadoop fs -dus /hbase/         <--- disk utilization for all HBase objects
sudo -u hbase /usr/local/hadoop/bin/hadoop fs -dus /hbase/<TABLE>  <--- disk utilization for a HBase table
sudo -u hbase /usr/local/hadoop/bin/hadoop fs -du  /hbase/<TABLE>  <--- disk utilization for a HBase table regions


helm repo add <REPO> <URL>
helm repo update
helm search repo <REPO>/<CHART> --versions
helm show values <REPO>/<CHART> > <NAME>-values.yaml
helm install <NAME> <REPO>/<CHART> --namespace <NAME> --create-namespace -f <NAME>-values.yaml
helm upgrade --install <NAME> <REPO>/<CHART> --namespace <NAME> --values <NAME>-values.yaml
helm list --all-namespaces || helm list -A
helm uninstall <NAME>

sudo iperf3 --server --bind <ADDRESS> --affinity 1
sudo iperf3 --client <DST ADDRESS> --bind <ADDRESS> --affinity 1
sudo iperf3 --client <DST ADDRESS> --bind <ADDRESS> --udp --affinity 1

sudo ip link add bridge0 type bridge
sudo ip link set <INTERFACE> master bridge0
sudo ip address add <ADDRESS>/24 dev bridge0
sudo ip link set dev bridge0
sudo ip link set dev bridge0 up
sudo ip route del <DST ADDRESS> via <GATEWAY> dev <INTERFACE>
sudo ip route add <DST ADDRESS> via <GATEWAY> dev <INTERFACE> metric 100
sudo ip route add default via <GATEWAY>
sudo ip route change default via <GATEWAY> dev <INTERFACE> metric 100
sudo ip link set <INTERFACE> down

sudo iptables -n -L -v
sudo vi /etc/sysconfig/iptables
sudo /etc/init.d/iptables reload

## JunOS Rooter Router
console port (RJ45 rollover cable <-> USB): ls -1 /dev | grep -E '(USB|ACM)'; screen /dev/tty.???? 9600
help topic ?
help reference ?
help apropos ?
help syslog <TAG>
show chassis fabric summary
show chassis environment
show chassis power
show chassis fan
show virtual-chassis
show system storage
show chassis alarms
show system alarms
show system core-dumps
show system uptime
show system commit
show log messages | last 10
show | compare rollback 1
show configuration | display set
show interfaces * terse | no-more
show interfaces * terse | except \.
show interfaces <PATTERN> | display set
show interfaces <INTERFACE> statistics
show route <ADDRESS[/SUBNET]> detail # lower number has priority
show route forwarding-table
show route table
show ethernet-switching table | match <MAC>
show lacp interfaces <LABLE> extensive
show firewall log
clear interface statistics <INTERFACE|all>
monitor interface <INTERFACE>
monitor traffic matching (src || dst <ADDRESS>)&&tcp&&port <PORT> write-file file.pcap count 150
ping <ADDRESS> interval 0.1 size 1472 do-not-fragment count 2000
traceroute <ADDRESS> bypass-routing inet6 interface <INTERFACE>
disable interface <INTERFACE>
set interface <INTERFACE> [<unit#>] disable
delete interface <INTERFACE> [<unit#>] disable
enable interface <INTERFACE>
request system storage cleanup dry-run
request system reboot
request system power-off

https://kubernetes.io/docs/reference/kubectl/generated/
kubectl auth can-i <list|create|edit|delete> <RESOURCE|pods>
kubectl config current-context
kubectl config get-contexts
kubectl config get-users
kubectl config use-context <NAME>
kubectl config view
kubectl get pods -A -o wide
kubectl get nodes -o wide
kubectl describe node
kubectl label node <NAME> <KEY>=<VALUE> (spec.template.spec.nodeSelector.<KEY>: <VALUE>)
kubectl apply -f deployment.yaml
kubectl get -n <NAMESPACE> all
kubectl get -n <NAMESPACE> <KIND>/<NAME>
kubectl get -n <NAMESPACE> <KIND>/<NAME> -o yaml
kubectl get -n <NAMESPACE> pods
kubectl get -n <NAMESPACE> <KIND>/<NAME> -o jsonpath='{.data.something}'
kubectl get -n <NAMESPACE> <KIND>/<NAME> -o jsonpath='{.spec.clusterIPs[0]}'
kubectl get -n <NAMESPACE> secret/<NAME> -o jsonpath='{.data.password}' | base64 --decode | xxd
kubectl events -n <NAMESPACE> <KIND>/<NAME> --follow
kubectl logs -n <NAMESPACE> <NAME> --follow
kubectl run <NAME> --image=<IMAGE:TAG> -it --rm -- /bin/sh
kubectl run alpine --image=alpine:latest -it --rm --env="FOO=${BAR}" -- /bin/sh
kubectl exec -n <NAMESPACE> deployment/<NAME> -it -- <COMMAND>
kubectl exec -n <NAMESPACE> deployment/<NAME> -it -- /bin/sh
kubectl patch deployment/<NAME> --patch-file patch.yaml
kubectl replace -f deployment.yaml --force
kubectl rollout -n <NAMESPACE> restart deployment/<NAMES>    <--- handle jiggle
kubectl scale -n <NAMESPACE> deployment/<NAME> --replicas=0  <--- handle jiggle
kubectl scale -n <NAMESPACE> deployment/<NAME> --replicas=3  <--- handle jiggle
kubectl delete -n <NAMESPACE> deployment/<NAME>
kubectl cordon <NODE NAME>    <--- kube maintenance: prevent new pods
kubectl drain <NODE NAME> --ignore-daemonsets --delete-emptydir-data --force --grace-period=300 --timeout=300s  <--- kube maintenance
kubectl drain <NODE NAME>     <--- kube maintenance: drain options
  --ignore-daemonsets         <--- kube maintenance: skip daemonset pods (they should be running on all nodes)
  --delete-emptydir-data      <--- kube maintenance: delete pods using emptydir volumes
  --force                     <--- kube maintenance: force deletion of pods not managed by controllers
  --grace-period=300          <--- kube maintenance: wait time before force-killing pods
  --timeout=300s              <--- kube maintenance: maximum time to wait for drain to complete
kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=<NODE NAME>  <--- maintenance: lingering pods?
kubectl delete -n <NAMESPACE> pod/<NAME> --force --grace-period=0  <--- kube maintenance: remove lingering pod(s)
sudo apt-get update && sudo apt-get upgrade --yes && sudo reboot  <--- kube maintenance: whatnot
sudo dnf clean all && sudo dnf upgrade -y && sudo dnf needs-restarting && sudo reboot  <--- kube maintenance: whatnot
sudo systemctl --failed       <--- kube maintenance: whatnot
kubectl uncordon <NODE NAME>  <--- kube maintenance: allow new pods
kubectl rollout -n <NAMESPACE> restart deployment/<NAMES>   <--- kube maintenance: rebalance pods


jinja string concatenation: "string1" ~ "string2"
jinja string formatting:    "foo %s" % 'bar' or "foo {}".format(bar)
jinja map filter:           items | map('attribute', 'key')
jinja regex replace:        string | regex_replace('pattern', 'replacement')

logger -t "<TAG>" -p <FACILITY.PRIORITY> "<MESSAGE>"
logger -p <FACILITY.PRIORITY> -f /path/to/file/with/message
FACILITIES='auth authpriv cron daemon ftp kern lpr mail news syslog user uucp local0 local1 local2 local3 local4 local5 local6 local7'
PRIORITIES='emerg alert crit err warning notice info debug'
for f in $FACILITIES; do
for p in $PRIORITIES; do
logger -p $f.$p "$PROG[$$]: testing $f.$p"
done
done

lsblk
sudo pvdisplay
sudo vgdisplay
sudo lvdisplay
sudo pvcreate /dev/nvme0n1 /dev/nvme1n1 /dev/nvme2n1
sudo vgcreate vg_data /dev/nvme0n1 /dev/nvme1n1
sudo lvcreate --size 250G --name lv_lxd vg_data
sudo lvresize --resizefs --size +<PE SIZE FREE - 0.1>G <LV PATH> --test
lsblk --output MOUNTPOINT,UUID
sudo vi /etc/fstab
sudo systemctl daemon-reload
## Mount a LV in rescue mode
lvm vgscan -v
vgchange -a y "<vg_name>"
lvm lvs --all
mkdir /mnt/tmp_root
mount /dev/<vg_name>/<lv_name> /mnt/tmp_root


sudo lshw -class memory -json


sudo lsof -i[TCP|UDP][@host][:port]  <--- network connections for all processes
sudo lsof -p <PID>                   <--- All open files for a specific PID
sudo lsof -c <COMMAND>               <--- All open files for a specific command
sudo lsof -u <USERNAME>              <--- All open files for a specific username


tr '[:upper:]' '[:lower:]'  <--- lowercase
awk '{print tolower($0)}'   <--- lowercase


lxc list
lxc info <name>
lxc image list images: | grep -i <...>
lxc profile create <name>
lxc profile edit <name>
lxc init <source> <name> (container)
lxc init <source> <name> < config.yaml
lxc launch <source> <name> --vm [--profile ...] [--config ...]
lxc init <source> <name> --vm --config limits.cpu=4 --config limits.memory=4GiB --device root,size=32GiB
lxc init images:alpine/edge <name> --vm --config security.secureboot=false --config ...
lxc config get <name> <key>
lxc config set <name> <key>=<value>
lxc config unset <name> <key>
lxc start <name>
lxc start <name> --console
lxc console <name>
lxc console <name> --show-log
lxc file pull <name>/path/to/file /local/path/to/file
lxc file pull -r <name>/path/to/dir /local/path/to/dir
lxc file push /local/path/to/file <name>/path/to/file
lxc file push -r /local/path/to/dir <name>/path/to/dir
lxc file edit <name>/path/to/file
lxc file mount <name>/path/to/dir /local/path/to/dir
lxc file delete <name>/path/to/file
lxc exec <name> -- <command>
lxc exec <name> --env <ENVVAR>=<value> -- <command>
lxc exec <name> --user <name> --group <name> --cwd /path/to/dir -- <command>
lxc snapshot <name>
lxc snapshot <name> <snapshot name (default: snap0)>
lxc config set <name> snapshot.schedule "0 6 * * *"
lxc config show <name>/<snapshot name>
lxc restore <name>/<snapshot name>
lxc restore <name>/<snapshot name> --stateful
lxc export <name> (default: ./<name>.tar.gz) <--- 1.6GB with two snapshots
lxc export <name> --instance-only --optimized-storage (when using btrfs or zfs storage) <--- 517MB
lxc export <name> --instance-only --optimized-storage --compression=bzip2 <--- 463MB
lxc export <name> /file/path/full-backup.tar.(gz|bz2|...)
lxc import /path/to/backup.tgz
lxc import /path/to/backup.tgz --storage <pool>
lxc import /path/to/backup.tgz <name>
lxc delete show <name>/<snapshot name>
lxc config set <name> security.protection.delete=true
lxc config unset <name> security.protection.delete --property
lxc delete <name>


sudo -iu root mtr -rwc 15 <ADDRESS> (-r/--report-wide, -n/--no-dns)
sudo -iu root mtr -rwnc 100 -4 -s 1472 <ADDRESS>


ping -q -s 1472 -M do -c 10 <ADDRESS> (-s size MTU-28 <- IPv4 or MTU-48 <- IPv6) (-M do = prohibit fragmentation)
sudo -iu root ping -q -s 1472 -M do -i .01 -c 2000 <ADDRESS>
ping: -s size MTU minus 28 for IPv4 or MTU minus 48 for IPv6
ping: -M do = prohibit fragmentation
nping --tcp-connect --dest-port 80 --count 100 --delay 100ms <ADDRESS>
sudo -iu root traceroute -T -p 80 <ADDRESS>


## Find a process by port using nestat and ps
netstat -nP -iTCP           <--- tcp
netstat -anv | grep <PORT>  <--- any protocol matching port, lists the <PID>
ps -Ao user,pid,command | grep -v grep | grep <PID> <--- find <PID> for the port


netstat --inet              <--- Connected sockets
netstat --inet --listening  <--- Server sockets
netstat --inet --all        <--- Both connected and server sockets
netstat --inet ... -p       <--- Identify processes


## ss can be noisy and include more then what is required, use netstat instead
netstat --tcp | awk '{states[\$NF]++} END {for (state in states) printf \"%s: %d\n\",state,states[state]}' | sort -nrk2"


## WTF state capture:
ss -ant | tee ~/$(hostname).sockets.$(date '+%s')
ps -ef | tee ~/$(hostname).ps.$(date '+%s')
top -b -n 1 | tee ~/$(hostname).top.$(date '+%s')


sudo exportfs -v                        <--- check nfs
sudo systemctl status nfs-kernel-server <--- check nfs
sudo showmount -e localhost             <--- check nfs
df -h /srv/nfs                          <--- check nfs


nftables - A modern Linux kernel packet classification framework - https://wiki.nftables.org/
sudo nft list tables [<FAMILY:ip|arp|ip6|bridge|inet|netdev>]
sudo nft list table <TABLE>
sudo nft -n -a list table <TABLE>
nft list chain <TABLE> <CHAIN>
sudo nft 'add chain [<FAMILY>] <TABLE NAME> <CHAIN NAME> \
  { type <TYPE> hook <HOOK> [device <DEVICE>] priority <PRIORITY>; [policy <POLICY>;] [comment <COMMENT>;] }
sudo nft 'add table ip filter'
sudo nft 'add chain ip filter input { type filter hook input priority 0; }'
sudo nft 'add chain ip filter output { type filter hook output priority 0; }'
sudo nft 'add rule <TABLE> <CHAIN> <FAMILY> ...'
sudo nft 'add rule filter output ip daddr 4.3.2.1 counter'
sudo nft 'insert rule <TABLE> <CHAIN> position <INT> ...'
sudo nft 'replace rule <TABLE> <CHAIN> handle <INT> ...'
sudo nft 'delete rule <TABLE> <CHAIN> handle <INT>'


nmcli general status
nmcli connection show
nmcli connection show --active
nmcli device status
nmcli device show <INTERFACE>
sudo nmcli connection up|down id <CONNECTION NAME>
sudo nmcli device disconnect|connect iface <INTERFACE>
sudo nmcli connection edit con-name <CONNECTION NAME>   <--- edit new
sudo nmcli connection edit <CONNECTION NAME>            <--- edit existing
sudo nmcli connection delete id <CONNECTION NAME>
nmcli radio wifi [on|off]
nmcli device wifi list|rescan
sudo nmcli device wifi connect <SSID|BSSID> password <PASSWORD>
sudo nmcli connection add con-name br0 ifname br0 type bridge stp off
sudo nmcli connection modify br0 ipv4.addresses '<ADDRESS>/24'
sudo nmcli connection modify br0 ipv4.gateway <ADDRESS>
sudo nmcli connection modify br0 ipv4.dns <ADDRESS>
sudo nmcli connection up br0
sudo nmcli connection modify <connection-name> +ipv4.routes "<NETWORK/CIRD> <GATEWAY> [<METRIC>]"
sudo vi /etc/NetworkManager/system-connections/<INTERFACE>.nmconnection <--- Fedora/NetworkManager
+ route27=<NETWORK/CIRD>,<GATEWAY>[,<METRIC>]
sudo nmcli connection reload
sudo nmcli connection up <CONNECTION NAME>
ip route show
sudo ip route add 192.168.100.123/32 via 192.168.100.1 dev en0 <--- force a route
ip neigh show <--- instead of arp -a
sudo ip neigh del 192.168.100.123 dev en0 <--- remove a route

echo | openssl s_client -connect <ADDRESS>:443 -servername <HOSTNAME> [-showcerts || -nextprotoneg '' || -tlsextdebug]
echo | openssl s_client -connect <ADDRESS>:443 -servername <HOSTNAME> 2>&1 | openssl x509 -noout -subject -enddate
echo | openssl s_client -connect <ADDRESS>:443 | tee /dev/tty | openssl x509 -noout -dates
openssl verify -CAfile /path/to/ca.pem /path/to/cert.pem
openssl rand -base64 16
nmap --script ssl-enum-ciphers -p 443 --script-args=tls.servername=<HOST> <HOST|ADDRESS>
nmap --script ssl-cert --script-args=tls.servername=<HOST> <HOST|ADDRESS>
Mozilla Certificate Authority (CA): https://wiki.mozilla.org/CA/Included_Certificates
curl -sL https://ccadb-public.secure.force.com/mozilla/IncludedCACertificateReportCSVFormat | grep Apple


sudo vi /etc/sysctl.d/50-enable-forwarding.conf
sysctl net.ipv4.ip_forward
echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward
sysctl net.ipv6.conf.default.forwarding
echo 1 | sudo tee /proc/sys/net/ipv6/conf/default/forwarding
# Enable forwarding for dual stack
net.ipv4.ip_forward=1
net.ipv6.conf.all.forwarding=1


openssl passwd -6 '<PASSWORD>' <--- typically 5000 rounds?
sudo apt install --yes whois; mkpasswd -m sha-512 -S 'saltness' -R 5000 '<PASSWORD>'
pip install passlib; python3 -c "from passlib.hash import sha512_crypt; print(sha512_crypt.using(rounds=5000, salt='saltness').hash('<PASSWORD>'))"


[git] diff -u file.ext > file.ext.patch <--- create a unified patch
patch --verbose file.ext file.ext.patch <--- apply or reverse a [unified] patch
patch --verbose --input file.ext.patch --output file.ext.patched file.ext 


# install podman and configure the podrunner user account
# https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html <--- quadlet-generated systemd units
sudo apt install -y podman systemd-container <--- includes machinectl
sudo useradd --create-home --user-group --shell /bin/bash podrunner
echo "podrunner:100000:65536" | sudo tee -a /etc/subuid
echo "podrunner:100000:65536" | sudo tee -a /etc/subgid
sudo loginctl enable-linger podrunner
sudo passwd -S podrunner <--- should be locked, e.g. podrunner L 2025-08-16 0 99999 7 -1
sudo machinectl shell podrunner@.host /usr/bin/bash <--- "login" shell to podrunner
sudo systemctl --user -M podrunner@ status <SERVICE>
sudo journalctl --user -M podrunner@ -flu <SERVICE>
# podman on macos via brew
brew install podman
podman machine list
podman machine init --now <NAME>
podman machine init --cpus 4 --memory 2048 --disk-size 100 -v "${HOME}/projects":/shared/projects <NAME>
podman machine inspect <NAME>
podman system connection list
podman system connection default <NAME>
podman machine start <NAME>
podman build --tag <TAG:VERSION> .
podman images
podman --connection <NAME> images
podman run --rm --interactive --tty --publish <PORT>:<PORT>/tcp --name <NAME> <TAG:VERSION> <CMD:/bin/sh>
podman run --rm -it alpine:latest /bin/sh
podman run --rm --detach --publish <PORT>:<PORT>/tcp --name <NAME> <TAG:VERSION>
podman run --rm -v /shared/projects/foo:/bar alpine:latest ls -la /bar
podman run --rm "debian:bookworm-slim" bash -c 'numfmt --to iec $(echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE))))' <--- 2.0G
podman generate kube <NAME> > pod.yaml
podman generate kube --service <NAME> > service.yaml
sudo vi /etc/containers/registries.conf
grep -v -E '^#|^$' /etc/containers/registries.conf
[[registry]]
prefix = "registry.lab"
location = "registry.lab"
insecure = true
blocked = false
podman tag localhost/<TAG:VERSION> registry.lab/<TAG:VERSION>
podman push registry.lab/<TAG:VERSION>
podman save --output image.tar <TAG:VERSION>
podman save --compress --format docker-dir --output <DIR> <TAG:VERSION> && tar cf <DIR>.tar <DIR>
cat <DIR>.tar | podman import - <TAG:VERSION>
podman system prune --all
podman machine stop <NAME>
podman machine rm


## Check for the need to reboot to finalize a security or kernel update:
if [[ -s /var/run/reboot-required ]]; then cat /var/run/reboot-required; else echo "System reboot NOT required"; fi


## Retry forloop
for i in {1..5}; do retry-some-command && break || sleep 10; done  <--- retry 5 times


resolvectl status                    <--- dns system configuration
sudo resolvectl statistics           <--- dns system statistics
resolvectl query <HOSTNAME|ADDRESS>  <--- dns resolution
resolvectl query --interface=vbr1s0 --type=AAAA --json=short <HOSTNAME|ADDRESS>


rpcinfo -p [host]   <--- Dynamically assigned ports for RPC services


rsync -avz -e "ssh -i /Users/some/.ssh/key" --dry-run /some/source/dir foo:~/some/target/dir/


## Saltiness
* https://github.com/saltstack/
* https://docs.saltproject.io/en/latest/py-modindex.html
* https://docs.saltproject.io/en/latest/ref/states/requisites.html
* https://docs.saltproject.io/en/latest/ref/states/all/index.html
* https://docs.saltproject.io/en/latest/ref/states/all/salt.states.test.html <--- test.succeed_without_changes

sudo salt '<pattern>|*' <function>.<action> <arguments> --out json

sudo salt '*' state.highstate           <--- Run the complete state tree defined in top.sls
sudo salt '*' state.apply [state]       <--- Run a specific state or orchestration (preferred method)
sudo salt '*' state.apply test=true --state-output=changes --state-verbose=False
sudo salt '*' state.sls state           <--- Run a specific SLS file
sudo salt '*' state.show_sls some.thing <--- Verify file syntax
sudo salt '*' cmd.run 'tail -100 /var/log/salt/minion | grep -i error'

* https://docs.saltproject.io/en/latest/ref/modules/all/salt.modules.ipmi.html <--- ????

# system
sudo salt '*' service.restart <NAME.service>
sudo salt '*' status.diskusage
sudo salt '*' status.all_status --out json --out-file all_status.json
sudo salt '*' network.interfaces

sudo salt-run manage.status                     # List minions up/down (manage.up|alived|down)
sudo salt '*' --preview-target
sudo salt '*' test.ping|version                 # Ping (not ICMP) minions or show salt version
sudo salt --pcre 'node[1-3]-(dev|qa)' test.ping # Match a PCRE pattern instead shell glob
sudo salt --list 'node1,node3,node5' test.ping  # Match a comma-separated list of minions
sudo salt '*' saltutil.refresh_pillar           # Refresh pillar
sudo salt '*' pillar.items                      # 
sudo salt --pillar 'role:prod*'                 # Match a pillar value to identify minions
sudo salt --ipcidr '192.168.123.0/24'           # Match a CIRD or IP address

sudo salt '*' file.list_backups /path/to/file   # Include: - backup: minion
sudo salt '*' file.restore_backup /path/to/file 99 <--- rollback to 99, creates v 101
sudo salt '*' file.delete_backup /path/to/file 100

sudo salt '*' grains --doc
sudo salt '*' saltutil.refresh_module           # Refresh grains
sudo salt '*' grains.ls                         # List grains (minion system properties)
sudo salt --grain os:Fedora grains.items        # Match all Fedora minions and list grain values (system properties)
sudo salt '*' match.grain 'os:Debian'           # 
sudo salt foo01 grains.setval deployment bar    # Set the grain deployment to a value (/etc/salt/grains)
sudo salt foo01 grains.setval role ['bar', ...] # Set the grain role to a list of values (/etc/salt/grains)

sudo salt '*' cp --doc
sudo salt '*' cp.get_file salt://nginx/nginx.conf /etc/nginx/nginx.conf     # Copy nginx.conf to all web* matching
sudo salt '*' cp.get_file_str /etc/nginx/nginx.conf                         # Displays the content of nginx.conf
sudo salt '*' cp.get_template salt://nginx/nginx.conf /etc/nginx/nginx.conf # Similar to get_file but execute the templating system
sudo salt '*' cp.get_dir salt://etc/nginx/ /etc/nginx/                      # Copy a directory of files from master to minion
sudo salt '*' nginx.signal reload                                           # Reload NGINX configuration sending a SIGNHUP

sudo salt-run jobs.active
sudo salt-run jobs.lookup_jid <JOB ID>
sudo salt 'NODE' saltutil.running
sudo salt 'NODE' saltutil.kill_job <JOB ID>


sar -pd -n DEV,EDEV -u ALL 5 24 (disk,network,cpu activity every 5 seconds for 24 measurements)
sar -dp (just disk activity)
iostat -dmx (like sar -dp)
sudo apt install --yes nvme-cli; sudo nvme smart-log /dev/nvme1n1
sudo fio --name=nvme-test --filename=/dev/nvme1n1 --direct=1 --bs=4k --size=1G --numjobs=4 --time_based --runtime=60 --group_reporting


sed -i 's|foo|bar|g'  <--- s (substitute), g (global)
sed -i 'y|abc|ABC|'   <--- y (transliterate), character-by-character like tr 'abc' 'ABC'
sed '/pattern/d'      <--- d (delete)
sed '/pattern/d'      <--- d (delete) lines matching pattern
sed -i '8d'           <--- d (delete) line 8
sed '1,5d'            <--- d (delete) lines 1-5
sed '/start/,/end/d'  <--- d (delete) from start pattern to end pattern
sed '/pattern/p'      <--- p (print)
sed '/pattern/a\text' <--- a (append)
sed '/pattern/i\text' <--- i (insert)
sed -i '8i|thing|'    <--- i (insert) thing at line 8


brew install coreutils <--- shred
shred --verbose --force --zero --iterations 25 /dev/sda99


ssh -L <PORT>:localhost:<PORT> -N -l <USER> <HOST|ADDRESS>
ssh-keygen -t rsa -b 4096 -f /home/natroyer/.ssh/example_rsa
ssh-keygen -t ecdsa -b 521 -f /home/natroyer/.ssh/example_ecdsa
ssh-keygen -t ed25519 -f ~/.ssh/example_ed25519
ssh-keygen -p -f ~/.ssh/example_ecdsa
ssh-keygen -R <ADDRESS|HOSTNAME>


stat --format='mtime:%y bytes:%s %n' /path/to/some/file


strace -o output.trace <COMMAND>             # save trace output to a file
strace -f -ff -o filename <COMMAND>          # save child trace process output to a separate file
strace -p <PID>                              # attach to a running process and trace system calls
strace -e trace=network,read,write <COMMAND> # trace network system calls
strace -e trace=read -e read=4 <COMMAND>     # print the transferred data in both hexadecimal and ASCII


systemctl status
systemctl list-units
systemctl --failed
sudo systemctl reset-failed


[ -d ${SOURCE} -a ! ${SOURCE} -ef ${TARGET} ]; tar cf - ${SOURCE} | (cd ${TARGET}; tar xvf -)  <--- tar pipe


<some command> | tee /dev/tty | <some command> <--- View the content on console and send to pipe


sudo -iu root tcpdump -nn
sudo -iu root tcpdump -w filename [-c count] [-i interface] [-s snap-length] [expression]
sudo -iu root tcpdump -nnvvS net <ADDRESS> and src not <ADDRESS> and not <ADDRESS>
sudo -iu root tcpdump -s 1600 -i any -nn tcp port <PORT> and host <ADDRESS> -Z <USER> -w ~<USER>/$(hostname)-$(date '+%s').pcap
sudo -iu root tcpdump -s 1600 -i any -nn net <ADDRESS> and 'tcp[tcpflags] & (tcp-rst) != 0'
sudo -iu root tcpdump -s 1600 -i any -nn 'not (src <ADDRESS> and port <PORT>)'


terraform -chdir=/path/to/main.tf init
terraform -chdir=/path/to/main.tf validate
terraform -chdir=/path/to/main.tf plan
terraform -chdir=/path/to/main.tf apply -auto-approve
terraform -chdir=/path/to/main.tf destroy
terraform -chdir=/path/to/main.tf apply -destroy -auto-approve

sudo systemctl status cloud-init
sudo systemctl status cloud-init-local
sudo systemctl status cloud-init-network
sudo systemctl status cloud-config
sudo systemctl status cloud-final
sudo cat /var/log/cloud-init-output.log
sudo cat /var/log/cloud-init.log
sudo cloud-init status --wait
sudo cloud-init query ds
sudo ls -l /var/lib/cloud/seed/nocloud/
sudo cat /var/lib/cloud/seed/nocloud/user-data


## Tmux Terminal Multiplexer
┌──────────────────────┐
│┌────────────────────┐│
││┌────────┐┌────────┐││
│││ SHELL$ ││ SHELL$ │││
││└─ PANE ─┘└─ PANE ─┘││
│└─ WINDOW(S) ────────┘│
└─ SESSION(S) ─────────┘
tmux new-session -s <NAME>                <--- start a new session
tmux new -s <NAME>                        <--- start a new session
tmux new -s <NAME> -n <NAME>              <--- start a new session named <NAME>
tmux new -s <NAME> -d                     <--- start a new session detached
tmux new -s <NAME> -d 'command(s) to run' <--- start a new session detached, running a command, session exits when command exits
tmux new -s 'tri-panel' \; split-window -h -p 66 \; split-window -h \;
tmux list-sessions
tmux ls
tmux attach                               <--- attach the first session
tmux attach -t <NAME>                     <--- attach a session by name
tmux kill-session -t <NAME>
Prefix ? <--- list predefined keybindings and associated commands
Prefix $ <--- rename session
Prefix d <--- detach session
Prefix c <--- create a new window
Prefix , <--- rename window
Prefix w <--- list of windows with a preview
Prefix f <--- find a window by name
Prefix <ARROW>  <--- move to window pane in direction of <ARROW>
Prefix ! <--- create a window from the window active pane
Prefix z <--- enter/exit full window zoom of a window pane
Prefix : <--- enter command mode
Prefix [ <--- enter copy mode (use q to exit), ...arrow around
even-horizontal      <--- stack all panes horizontally, left to right
even-vertical        <--- stack all panes vertically, top to bottom
main-horizontal      <--- create one larger pane on the top and smaller panes underneath
main-vertical        <--- creates one large pane on the left side of the screen, stacks the rest vertically on the right
new-window -n <NAME> <--- new window with name <NAME>
new-window -n <NAME> "command(s)"   <--- new window with name <NAME> running "command(s)", window closes when command exits
set-window-option synchronize-panes on <--- synchronize command entry on multiple panes
tmux send-keys -t [session]:[window].[pane] 'command(s) to run' C-m


top -b -n 1 -o +RES -E m -e m  <--- top 'one shot' sorted by RES memory
top -c -u <USER>
top -d 3 -n 5 -b -c
mpstat -P ALL 3 1; vmstat 3 2; free -m;
pidstat


## Configure vi to search .bash_history: ESC + /
echo "set -o vi" >> ~/.bash_profile && source ~/.bash_profile
vi :10,20delete   <--- delete lines 10 through 20
vi :10,$delete    <--- delete from line 10 to the end of file
vi :.,+4delete    <--- delete from current line and next 4 lines
vi dgg            <--- delete from current line to the beginning of the file
vi :set list      <--- show invisible characters (set: nolist)
vi :set number    <--- show line numbers (set: nonumber)
vi :%s/abc/123/g  <--- Find and replace abc with 123 globally


for i in $(seq 899 -1 890); do getent passwd ${i}; getent group ${i}; done  <--- check for user/group ids in range 890-899
sudo groupadd --system --gid 899 widgets
sudo useradd --system --uid 899 --gid 899 --no-create-home --shell /usr/sbin/nologin --comment "Widget XYZ" widget-xyz
sudo useradd --create-home --user-group --shell /bin/bash user-xyz
sudo usermod --append --groups widgets widget-xyz
sudo groupmod --users widget-xyz,user-xyz widgets
sudo userdel widget-xyz
sudo groupdel widget-xyz


sudo apt install libguestfs-tools; sudo virt-customize -a /path/to/vm.qcow2 --ssh-inject ubuntu:string:"ssh-ed25519 ..."


watch -n <SECONDS> <COMMAND>
watch -n 1 ip -s link show
watch -n 2 'netstat –tulpnc'
watch -n 2 'netstat -s | head -n 50'


xargs -n 1 -P 20 -I{} ssh ... {} 'ionice -c 3 ...'
xargs --max-args=1 --max-procs=20 -I{} ssh -q ... {} 'ionice -c 3 find ...'

uptime && sudo dmesg | tail && sar -n DEV 1 && free -m && top && vmstat 1 && mpstat -P ALL 1 && pidstat 1 && iostat -xz 1
